% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/summary_plbpsm.R
\name{summary.plbpsm}
\alias{summary.plbpsm}
\alias{print.summary.plbpsm}
\title{Summary for a PLBPSM fit}
\usage{
\method{summary}{plbpsm}(object, h_opt = NULL, X0 = NULL,
  dispersion = NULL, ...)

\method{print}{summary.plbpsm}(x, digits = max(3, getOption("digits") -
  3), signif.stars = getOption("show.signif.stars"), ...)
}
\arguments{
\item{object}{a fitted \code{plbpsm} object as produced by \code{plbpsm()}.}

\item{h_opt}{the bandwidth given for Spline-backfitting local estimator, default is \code{NULL}.}

\item{X0}{the new predict matrix for obtaining simultaneous confidence band.}

\item{dispersion}{a value for the dispersion parameter: not normally used.}

\item{...}{other arguments.}

\item{x}{a \code{summary.plbpsm} object produced by \code{summary.plbpsm()}.}

\item{digits}{controls number of digits printed in output.}

\item{signif.stars}{Should significance stars be printed alongside output.}
}
\value{
\code{summary.plbpsm} produces a list of summary information for a fitted \code{plbpsm} object.
\item{p.coeff}{is an array of estimates of the strictly parametric model coefficients.}
\item{p.t}{is an array of the \code{p.coeff}'s divided by their standard errors.}
 \item{p.pv}{is an array of p-values for the null hypothesis that the corresponding parameter is zero.
 Calculated with reference to the t distribution with the estimated residual
 degrees of freedom for the model fit if the dispersion parameter has been
 estimated, and the standard normal if not.}
 \item{m}{The number of smooth terms in the model.}
 \item{se}{array of standard error estimates for all parameter estimates.}
 \item{r.sq}{The adjusted r-squared for the model. Defined as the proportion of variance explained, where original variance and
 residual variance are both estimated using unbiased estimators. This quantity can be negative if your model is worse than a one
 parameter constant model, and can be higher for the smaller of two nested models! The proportion null deviance
 explained is probably more appropriate for non-normal errors. Note that \code{r.sq} does not include any offset in the one parameter model.}
\item{dev.expl}{The proportion of the null deviance explained by the model. The null deviance is computed taking account of any offset, so
\code{dev.expl} can be substantially lower than \code{r.sq} when an offset is present.}
 \item{edf}{array of estimated degrees of freedom for the model terms.}
\item{residual.df}{estimated residual degrees of freedom.}
 \item{n}{number of data.}
 \item{np}{number of model coefficients (regression coefficients, not smoothing parameters or other parameters of likelihood).}
\item{criterion}{The criterion to choose the penalty parameter lambda. \code{"GCV"} to use
generalized cross validation method and \code{"CV"} for cross validation}
\item{family}{The family object, specifying the distribution and link to use.}
\item{method}{'ALASSO' or 'SCAD' to penalize the coefficients for parametric part.}
 \item{formula}{the original PLBPSM formula.}
 \item{dispersion}{the scale parameter.}
 \item{pTerms.df}{the degrees of freedom associated with each parametric term
 (excluding the constant).}
 \item{pTerms.chi.sq}{a Wald statistic for testing the null hypothesis that the
 each parametric term is zero.}
\item{pTerms.pv}{p-values associated with the tests that each term is
 zero. For penalized fits these are approximate. The reference distribution
 is an appropriate chi-squared when the
scale parameter is known, and is based on an F when it is not.}
 \item{cov.scaled}{The estimated covariance matrix of the parameters.}
 \item{p.table}{significance table for parameters}
\item{p.Terms}{significance table for parametric model terms}
\item{gcv_opt}{The optimized gcv score.}
\item{cv_opt}{The optimized cv score.}
\item{bands}{A list of confidence bands for univaratie functions estimates.}
\item{mhat}{The estimated values for each linear or nonlinear term.}
}
\description{
Takes a fitted \code{plbpsm} object produced by \code{plbpsm()} and produces various useful summaries from it.
}
\examples{
 library(MASS)
 library(grpreg)
 library(BPST)
 data("eg1pop_dat")
 eg1_V2=eg1pop_dat[['V2']]
 eg1_T2=eg1pop_dat[['T2']]
eg1pop_rho03=eg1pop_dat[['rho03']]
sam=eg1pop_rho03[sample(1:dim(eg1pop_rho03)[1],100),]
lambda=10^(seq(-2,5,by=1))
data=sam
formula=Y~z1+z2+z3+z4+z5+z6+z7+z8+b(x1,x2,V=eg1_V2,Tr=eg1_T2,d=2,r=1,lambda=lambda)
# example 1
res=plbpsm(formula=formula,data=as.data.frame(data),VS=TRUE)
# example 12: ALASSO
res12=plbpsm(formula=formula,data=as.data.frame(data),VS=TRUE)
res10=plbpsm(formula=formula,data=as.data.frame(data),drop.intercept=TRUE)
# compare results under different settings
summary(res)
summary(res10)
summary(res12)

### GGAM-SMILE ###
data(eg1pop_poi2)
n=100
Npop=nrow(eg1pop_poi2)
ind.pop=(1:Npop)
sam.ind=sort(sample(ind.pop,n,replace=FALSE))
sam=eg1pop_poi2[sam.ind,]
data=sam
formula=Y~z1+u(z2)+u(z3)+b(x1,x2,V=eg1_V2,Tr=eg1_T2,d=2,r=1)
res_eg1_poi_add=plbpsm(formula=formula,data=as.data.frame(data),family='poisson')
summary(res_eg1_poi_add)
res_ggams=summary(res_eg1_poi_add)

# The following is the SBL estimator for u(z2)
res_ggams$bands[[1]]$est
}
